{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D,Flatten, Reshape,LSTM\n",
    "\n",
    "import keras.datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a non-linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some simulated data\n",
    "n=1000\n",
    "x=np.random.uniform(-6,6,n).reshape(-1,1)\n",
    "# generate Y as cosine of x.\n",
    "y=np.cos(x)+np.random.normal(0,.5,n).reshape(-1,1)\n",
    "train_idx=list(range(0,int(.9*n)))\n",
    "test_idx=list(range(int(.9*n),n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear session -- helps manage memory\n",
    "K.clear_session()\n",
    "\n",
    "# make model object\n",
    "mod=Sequential()\n",
    "\n",
    "# add model layers\n",
    "mod.add(Dense(10,activation='relu',input_shape=(1,)))\n",
    "mod.add(Dense(10,activation='relu'))\n",
    "mod.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# specify model estimation strategy -- minimize mse loss using adam\n",
    "mod.compile('adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "# fit model\n",
    "mod.fit(x[train_idx,:],y[train_idx],epochs=300,verbose=0)\n",
    "\n",
    "# Generate predictions\n",
    "yhat=mod.predict(x[test_idx])\n",
    "\n",
    "# print metrics\n",
    "print(metrics.mean_squared_error(y[test_idx],yhat))\n",
    "\n",
    "# Produce visualization\n",
    "plt.scatter(x[test_idx],yhat)\n",
    "plt.scatter(x[test_idx],y[test_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image parsing --  convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=datasets.load_digits()\n",
    "\n",
    "n=len(digits['data'])\n",
    "train_idx=list(range(0,int(.9*n)))\n",
    "test_idx=list(range(int(.9*n),n))\n",
    "\n",
    "\n",
    "x=digits['data']\n",
    "y=keras.utils.to_categorical(digits['target'],10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=Sequential()\n",
    "mod.add(Reshape(target_shape=(8,8,1),input_shape=(64,)))\n",
    "mod.add(Conv2D(3,(4,4)))\n",
    "mod.add(Flatten())\n",
    "mod.add(Dense(10,activation='softmax'))\n",
    "\n",
    "mod.compile('adam','categorical_crossentropy')\n",
    "mod.fit(x[train_idx],y[train_idx],epochs=200,verbose=0)\n",
    "yhat=np.argmax(mod.predict(x[test_idx]),1)\n",
    "\n",
    "metrics.accuracy_score(np.argmax(y[test_idx],1),yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,5,figsize=(8,5))\n",
    "\n",
    "ax=ax.reshape(-1)\n",
    "for i in range(15):\n",
    "    ax[i].imshow(x[test_idx][i,:].reshape(8,8),cmap='Greys')\n",
    "    ax[i].text(-1,-1,yhat[i],color='green', fontsize=15)\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data for this example is the unemployment rate, furnished by BLS, distributed by the St. Louis Federal Reserve.\n",
    "\n",
    "> U.S. Bureau of Labor Statistics, Civilian Unemployment Rate [UNRATE], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UNRATE, October 17, 2017.\n",
    "\n",
    "Data is formatted and stored in a pickle for convenience. \n",
    "To see how this file was generated, or regenerate the pickle, you can examine the file data_gen.py This will require an API key from fred. \n",
    "\n",
    "Data is unemployment data with 36 lags, first, second differences and moving average included as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test=pickle.load(open(\"ts_example.pck\",'rb'))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# build model object\n",
    "mod=Sequential()\n",
    "\n",
    "# add layers\n",
    "# 100 gives output h(x) but also sets the memory capacity. Default returns output from last item in sequence\n",
    "mod.add(LSTM(100,input_shape=(36,4)))\n",
    "mod.add(Dense(1))\n",
    "\n",
    "# build model\n",
    "mod.compile(\"adam\",'mse')\n",
    "\n",
    "# fit model\n",
    "mod.fit(x_train,y_train,epochs=100,batch_size=200,verbose=0)\n",
    "\n",
    "#generate predictions\n",
    "yhat=mod.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# print metrics\n",
    "print(metrics.mean_absolute_error(yhat,y_test))\n",
    "\n",
    "# Produce nice-looking plot\n",
    "plt.plot(yhat)\n",
    "plt.plot(y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
